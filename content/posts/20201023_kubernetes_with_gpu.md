---
title: "Kubernets(ì¿ ë²„ë„¤í‹°ìŠ¤) with GPU êµ¬ì¶•í•˜ê¸°"
date: 2020-10-23T10:56:19+09:00
draft: false
---

# Intro
Kubernetesì—ì„œ GPUë¥¼ ì‚¬ìš©í•˜ë„ë¡ í™˜ê²½ì„ êµ¬ì¶•í•˜ê³  ì‚¬ìš©í•´ë³´ì.
ì—¬ê¸°ì„œëŠ” Kubernest í´ëŸ¬ìŠ¤í„°ê°€ êµ¬ì¶•ë˜ì–´ ìˆë‹¤ê³  ì „ì œí•˜ê³  ì§„í–‰í•œë‹¤. ì•„ì§ ì„¤ì¹˜ê°€ ë˜ì§€ ì•Šì•˜ë‹¤ë©´ [Kubernetes Cluster ì„¤ì¹˜í•˜ê¸°(ubuntu18.04)](https://healinyoon.github.io/2020/09/20200828_install_kubernetes_cluster_ubuntu/)ì„ ì°¸ê³ í•´ì„œ ì„¤ì¹˜ í›„ ì§„í–‰í•´ì•¼ í•œë‹¤.

# 1. Nvidia Plugin Pod ìƒì„±

### ref)

* [Nvidia k8s-device-plugin ê³µì‹ ì‚¬ì´íŠ¸](https://github.com/NVIDIA/k8s-device-plugin/tree/v1.12)
* [Nvidia docker ê³µì‹ ì‚¬ì´íŠ¸](https://github.com/NVIDIA/nvidia-docker)

## 1.1 ê°€ì¥ ì •ë³´ê°€ ë§ì•˜ë˜ YAMLìœ¼ë¡œ ì„¤ì¹˜, ê·¸ëŸ¬ë‚˜ ì‹¤íŒ¨

ì²˜ìŒì— [ì—¬ê¸°](https://likefree.tistory.com/15) ë§í¬ë¥¼ ì°¸ê³ í•˜ì—¬ ì§„í–‰í–ˆë‹¤.

ë‹¤ë§Œ ì•„ë˜ì™€ ê°™ì´ ë²„ì „ë§Œ ë³€ê²½í•˜ì—¬ ì‹¤í–‰í–ˆë‹¤.
```
$ kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.12/nvidia-device-plugin.yml
daemonset.extensions/nvidia-device-plugin-
daemonset-1.12 created
```

í•˜ì§€ë§Œ ì•„ë˜ ì´ìŠˆ ë°œìƒí•´ì„œ ì‹¤íŒ¨í–ˆë‹¤ â†“ â†“ â†“

## 1.2. ì´ìŠˆ

### 1.2.1. ì´ìŠˆ ë‚´ìš©
ì¿ ë²„ë„¤í‹°ìŠ¤ `1.15` ë²„ì „ ì´í•˜ë¥¼ ì„¤ì¹˜í–ˆì„ ê²½ìš° ë¬¸ì œ ì—†ê² ì§€ë§Œ, `1.16` ë²„ì „ ì´ìƒì„ ì„¤ì¹˜í–ˆì„ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤.
```
error: unable to recognize "https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.12/nvidia-device-plugin.yml": no matches for kind "DaemonSet" in version "extensions/v1beta1"
```
ì´ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë²„ì „ì´ ì—…ê·¸ë ˆì´ë“œ ë˜ë©´ì„œ, `Daemonset`ì˜ `extensions/v1beta1` ë²„ì „ì„ ë”ì´ìƒ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.  
â†’ 1) ë”°ë¼ì„œ ë²„ì „ì„ `apps/v1` ìœ¼ë¡œ ë³€ê²½í•˜ê³  `selector` objectë¥¼ ì¶”ê°€í•œ í›„  
â†’ 2) k8s-device-pluginì„ ë‹¤ì‹œ ì„¤ì¹˜í•˜ê³   
â†’ 3) ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ íŒŒì¼ë„ ì ì ˆí•˜ê²Œ ìˆ˜ì •í•´ì£¼ì—ˆë‹¤.  

### ref)

* [Kubectl convert ì°¸ê³  ìë£Œ](https://medium.com/star-systems-labs/kubectl-convert-update-api-versions-automatically-e669add17e3d)
* [No matches ì´ìŠˆ í•´ê²° ìë£Œ](ttps://www.kangwoo.kr/2020/02/17/pc%EC%97%90-kubeflow-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0-2%EB%B6%80-kubernetes-nvidia-device-plugin-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0/)  

> (ì°¸ê³ ) Pod ìƒì„± ì‹¤íŒ¨ì‹œ ì—ëŸ¬ ì •ë³´ í™•ì¸
```
$ kubectl describe pod {pod ëª…}
```

### 1.2.2. ë³€ê²½í•œ YAML íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ DaemonSet Pod ìƒì„±
ì´ì œ ì»¤ìŠ¤í„° ë§ˆì´ì§•í•œ YAML íŒŒì¼ë¡œ Podë¥¼ ìƒì„±í•´ë³´ì.
> gpu-plugin.yaml
```
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset-1.12
  namespace: kube-system
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        name: nvidia-device-plugin-ds
    spec:
      tolerations:
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      # This, along with the annotation above marks this pod as a critical add-on.
      - key: CriticalAddonsOnly
        operator: Exists
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      containers:
      - image: nvidia/k8s-device-plugin:1.11
        name: nvidia-device-plugin-ctr
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
      nodeSelector:
        gpus: "true"
```
ìœ„ì˜ ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ ì£¼ìš” ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

##### â‘  ë¦¬ì†ŒìŠ¤ ìœ í˜• = DaemonSet
```
kind: DaemonSet
```
    ë”°ë¼ì„œ ê¸°ë³¸ì ìœ¼ë¡œëŠ” ëª¨ë“  worker ë…¸ë“œ í•˜ë‚˜ì”© ë™ì‘í•˜ê²Œ í•œë‹¤.

##### â‘¡ RollingUpdate
`spec.selector.matchLabels.name`

```
name: nvidia-device-plugin-ds
```

`spec.template.matadata.labels.name` 

```
labels:
  name: nvidia-device-plugin-ds
```

name objectê°€ `nvidia-device-plugin-ds` ì¸ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•˜ì—¬ RollingUpdateë¥¼ ì„¤ì •í•œë‹¤.

##### â‘¢ node Label ì§€ì •

`spec.template.spec.nodeSelector` ë¡œ ì–´ëŠ ë…¸ë“œì˜ DaemonSetìœ¼ë¡œ ë„ì›Œì¤„ ê²ƒì¸ì§€ ë ˆì´ë¸”ë§í•´ì¤€ë‹¤.

```
nodeSelector:
  gpus: "true"
```

## 1.3. gpu-plugin DeamonSet Pod ì •ìƒ ë™ì‘ í™•ì¸
```
$ kubectl -n kube-system get pod -l name=nvidia-device-plugin-ds
NAME                                        READY   STATUS    RESTARTS   AGE
nvidia-device-plugin-daemonset-1.12-d7t2g   1/1     Running   0          48d
nvidia-device-plugin-daemonset-1.12-jmcg9   1/1     Running   0          48d
nvidia-device-plugin-daemonset-1.12-zhsqm   1/1     Running   0          4h8mubectl -n kube-system get pod -l name=nvidia-device-plugin-ds
NAME                                        READY   STATUS    RESTARTS   AGE
nvidia-device-plugin-daemonset-1.12-7kh27   1/1     Running   0          27m

$ kubectl -n kube-system logs  -l name=nvidia-device-plugin-ds
2020/07/01 05:02:30 Loading NVML
2020/07/01 05:02:30 Fetching devices.
2020/07/01 05:02:30 Starting FS watcher.
2020/07/01 05:02:30 Starting OS watcher.
2020/07/01 05:02:30 Starting to serve on /var/lib/kubelet/device-plugins/nvidia.sock
2020/07/01 05:02:30 Registered device plugin with Kubelet
```

### ğŸŒŸğŸŒŸ ì—¬ê¸°ì„œ ì ê¹! ğŸŒŸğŸŒŸ
ì¤‘ìš”í•œ ì‚¬í•­ì€ gpuë¥¼ ì‚¬ìš©í•˜ë ¤ëŠ” Worker nodeê°€ `gpus: "true"` ë ˆì´ë¸”ë§ì´ ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. 

* ë§Œì•½ GPUê°€ ìˆëŠ” nodeì¸ë° í•´ë‹¹ DeamonSetì´ ì˜¬ë¼ê°€ìˆì§€ ì•Šê±°ë‚˜
* ì‹ ê·œ Worker nodeë¥¼ ì¶”ê°€í•˜ë ¤ëŠ” ê²½ìš°

â‡’ `kubectl label nodes {Worker node ëª…} gpus=true` ë¡œ ë ˆì´ë¸”ë§ì„ í•´ì£¼ì.

# 2. GPU ê°œìˆ˜ í™•ì¸
ì´ì œ ì¿ ë²„ë„¤í‹°ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜ë¥¼ í™•ì¸í•´ë³´ì.  
master nodeì—ì„œ ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ê° worker nodeì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ GPU ê°œìˆ˜ê°€ ì¶œë ¥ëœë‹¤.
```
$ kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"
NAME            GPU
gpu-1080ti-XX   9
gpu-1080ti-XX   9
```

# 3. Podì—ì„œ ê·¸ë˜í”½ ì¹´ë“œ ëª…ë ¹ì–´ í…ŒìŠ¤íŠ¸

## 3.1. GPUë¥¼ ì‚¬ìš©í•˜ëŠ” Pod ìƒì„±í•˜ê¸°

### 3.1.1. YAML íŒŒì¼
> gpu-k8s.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: gpu-k8s
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:9.0-runtime
    command:
      - "/bin/sh"
      - "-c"
    args:
      - nvidia-smi && tail -f /dev/null
    resources:
      requests:
        nvidia.com/gpu: 2
      limits:
        nvidia.com/gpu: 2
```

### ref)
nvidia/cuda ë„ì»¤ ì´ë¯¸ì§€ ë²„ì „ì´ ë§ì§€ ì•Šì€ ì´ìŠˆ ë°œìƒ ì‹œ â‡’ ë„ì»¤ í—ˆë¸Œì—ì„œ ë§ëŠ” ì´ë¯¸ì§€ ë²„ì „ì„ ì°¾ì•„ì„œ ì‚¬ìš©í•´ì£¼ë©´ ëœë‹¤.

* [Docker Hub](https://hub.docker.com/r/nvidia/cuda/)
* [Kubernetes Resource Requestì™€ Limitì˜ ì´í•´](https://itchain.wordpress.com/2018/05/16/kubernetes-resource-request-limit/)
* [Schedule GPUs](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)

### 3.1.2. Pod ìƒì„± ë° í™•ì¸
```
$ kubectl apply -f gpu-k8s.yaml
pod/gpu-k8s created

$ kubectl get pods
NAME                                READY   STATUS    RESTARTS   AGE
gpu-k8s                             1/1     Running   0          12s
```

### 3.1.3. nvidia-smi í™•ì¸
```
$ kubectl logs gpu-k8s
Thu Jul  2 06:00:24 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:86:00.0 Off |                  N/A |
| 29%   30C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:AF:00.0 Off |                  N/A |
| 29%   31C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

## 3.2. 2ê°œì˜ Podë¥¼ ë„ì›Œì„œ gpu 4ê°œë¥¼ ëª¨ë‘ ì‚¬ìš©í•˜ê¸°
gpu-k8s2.yaml ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ íŒŒì¼ì„ í•˜ë‚˜ ë” ë§Œë“¤ì–´ì„œ ìœ„ì™€ ë™ì¼í•˜ê²Œ ì‹¤í–‰í•´ë³´ì.

### 3.2.1. ê²°ê³¼ í™•ì¸

```
$ kubectl get pods
NAME                                READY   STATUS    RESTARTS   AGE
gpu-k8s                             1/1     Running   0          2m44s
gpu-k8s2                            1/1     Running   0          2
```

### 3.2.2. nvidia-smi í™•ì¸

```
$ kubectl logs gpu-k8s2
Thu Jul  2 06:03:06 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:18:00.0 Off |                  N/A |
| 29%   31C    P8     7W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:3B:00.0 Off |                  N/A |
| 29%   33C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

## 3.3. ì»¨í…Œì´ë„ˆê°€ ë…¸ë“œì˜ ëª¨ë“  GPUë¥¼ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ í•˜ê³  ì‹¶ë‹¤ë©´

* requestì™€ limit ì„¤ì • ë¶€ë¶„ì„ ì—†ì• ì£¼ë©´ ëœë‹¤.
* íŠ¹ì´í•œ ì ì€ ì´ë¯¸ ë‹¤ë¥¸ íŒŒë“œì— GPUë¥¼ ëª¨ë‘ í• ë‹¹ í•´ì¤€ ìƒíƒœì—ì„œë„ íŒŒë“œ ìƒì„± ê°€ëŠ¥í•˜ë‹¤.

### 3.3.1. YAML íŒŒì¼
```
apiVersion: v1
kind: Pod
metadata:
  name: gpu-all
spec:
  containers:
  - name: gpu-container
    image: nvidia/cuda:9.0-runtime
    env:
    - name: DP_DISABLE_HEALTHCHECKS
      value: "xids"
    command:
      - "/bin/sh"
      - "-c"
    args:
      - nvidia-smi && tail -f /dev/null
```

### 3.3.2. Pod ì‹¤í–‰
```
$ kubectl apply -f gpu-all.yaml
pod/gpu-all created
```

### 3.3.3. í™•ì¸
```
$ kubectl get pods
NAME                                READY   STATUS    RESTARTS   AGE
gpu-all                             1/1     Running   0          50s
gpu-k8s                             1/1     Running   0          42m
gpu-k8s2                            1/1     Running   0          40m

$ kubectl logs gpu-all
Thu Jul  2 06:42:25 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:18:00.0 Off |                  N/A |
| 29%   32C    P8     7W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 108...  Off  | 00000000:3B:00.0 Off |                  N/A |
| 29%   33C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GeForce GTX 108...  Off  | 00000000:86:00.0 Off |                  N/A |
| 29%   31C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GeForce GTX 108...  Off  | 00000000:AF:00.0 Off |                  N/A |
| 29%   31C    P8     8W / 250W |      0MiB / 11178MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```